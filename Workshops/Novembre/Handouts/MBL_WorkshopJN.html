<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Population genetics workshop</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>


<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



</head>

<body>
<h1>Population genetics workshop</h1>

<h3>Welcome</h3>

<p>This excercise is going to expose you to several basic ideas in probability and statistics as well as show you the utility of using R for basic statistical analyses.  We&#39;ll do so in the context of a basic population genetic analysis.  </p>

<h3>The scenario</h3>

<p>As a biologist, you will learn what are the major patterns that are expected when the data you work with is clean. Using that expertise will save you from the mistake of misinterpreting error-prone data.   In population genetics, there are a number of patterns that we expect to see immediately in our datasets.  In this exercise you will explore one of those major patterns.  Rather than give it a way - let&#39;s begin some analysis and see what we find.  In the narative that follows, we&#39;ll refine our thinking as we go.  </p>

<h3>Introductory terminology</h3>

<ul>
<li>Single-nucleotide polymorphism (SNP):  A nucleotide basepair that is <em>polymorphic</em> (i.e. it has multiple types or <em>alleles</em> in the population)</li>
<li>Allele:  A particular variant form of DNA  (e.g. A partciular SNP may have the &ldquo;A-T&rdquo; allele in one DNA copy and &ldquo;C-G&rdquo; in another; We typically define a reference strand of the DNA to read off of, and then denote the alleles according to the reference strand base - so for example, these might be called simply the &ldquo;A&rdquo; and &ldquo;C&rdquo; alleles.  In many cases we don&#39;t care about the precise base, so we might call these simply the \( A_1 \) and \( A_2 \) alleles, or the \( A \) or \( a \) alleles, or the 0 and 1 alleles.) </li>
<li>Minor allele: The allele that is more rare in a population </li>
<li>Major allele: The allele that is more common in a population </li>
<li>Genotype: The set of alleles carried by an individual (E.g. AA, AC, CC; or AA, AA, and aa; or 0/0, 1/1, 2/2)</li>
<li>Genotyping array: A technology based on hybridization with probes and florensence that allows genotype calls to be made at 100s of thousands of SNPs per individual at an affordable cost.<br/></li>
</ul>

<h3>The data-set and basic pre-processing</h3>

<p>We will look at Illumina 650Y genotyping array data from the CEPH-Human Genome Diversity
Panel.  This sample is a global-scale sampling of human diversity with 52 populations in total.</p>

<p>The data were first described in Li et al (Science, 2008) and the raw files are available from the
following link:
<a href="http://hagsc.org/hgdp/files.html">http://hagsc.org/hgdp/files.html</a>.  These data have been used in numerous subsequent publications (e.g Pickrell et al, Genome Research, 2009) and are an important reference set.  A few technical details are that the genotypes were filtered with a GenCall score cutoff of 0.25 (a quality score generated by the basic genotype calling software).  Individuals with a genotype call rate <98.5% were removed, with the logic being that if a sample has many missing genotypes it may due to poor quality of the source DNA, and so none of the genotypes should be trusted.  Beyond this, to prepare the data for the workshop, we have filtered down the indiviudals to a set of 938 unrelated individuals.  (For those who are interested, the data are available as plink-formatted files `H938.bed` 
`H938.fam`, `H938.bim` from this link: <http://bit.ly/1aluTln>).  We have also extracted the basic counts of three possible genotypes.  </p>

<p>The files with these genotype frequencies are your starting points. </p>

<h3>Note about logistics</h3>

<p>We will use some of functions from the <code>dplyr</code> and <code>ggplot2</code> and <code>reshape2</code> libaries so first let&#39;s load them:</p>

<pre><code class="r">library(dplyr)
library(ggplot2)
library(reshape2)
</code></pre>

<p>If you get an error message saying there is no package titled <code>dplyr</code>,<code>ggplot2</code>, or <code>reshape2</code> you may need to first run <code>install.packages(&quot;dplyr&quot;)</code>,<code>install.packages(&quot;ggplot2&quot;)</code>, or<code>install.packages(&quot;reshape2&quot;)</code> to install the appropriate package. </p>

<p>We will not be outputting files - but you may want to set your working directory to the <code>sandbox</code> sub-directory in case you want to output some files. </p>

<p>The <code>MBL_WorkshopJN.Rmd</code> file has the R code that you can run.  I provide code for most steps, but some you will need ot devise for yourselves to answer the questions that are part of the workshop narrative. </p>

<h3>Initial view of the data</h3>

<p>Read in the data table:</p>

<pre><code class="r">g&lt;-read.table(&quot;../Data/H938_chr15.geno&quot;,header=T)
</code></pre>

<p>It will be read in as a dataframe in R.</p>

<p>And use the &ldquo;head&rdquo; command to see the beginning of the dataframe:</p>

<pre><code class="r">head(g)
</code></pre>

<p>You should see that there are columns each with distinct names.  </p>

<pre><code>CHR        SNP A1 A2 nA1A1 nA1A2 nA2A2
</code></pre>

<ul>
<li>CHR: The chromosome number.  In this case they are all from chromosome 2.</li>
<li>SNP: The rsid of a SNP is a unique identifier for a SNP and you can use the rsid to look up information about a SNP using online resource such as dbSNP or SNPedia. </li>
<li>A1: The minor allele at the SNP</li>
<li>A2: The major allele</li>
<li>nA1A1 : The number of A1/A1 homozygotes</li>
<li>nA1A2 : The number of A1/A2 homozygotes</li>
<li>nA2A2 : The number of A2/A2 homozygotes</li>
</ul>

<h3>Calculate the number of counts at each locus</h3>

<p>Next compute the total number of observations by summing each of the three possible genotypes.  Here we use the <code>mutate</code> function from the <code>dplyr</code> library to do the addition and add a new column to the dataframe in one nice step.  (Note: You could also use the <code>colSums</code> function from the base R library).   </p>

<pre><code class="r">g &lt;- mutate(g, nObs=nA1A1+nA1A2+nA2A2)
</code></pre>

<p>Run <code>head(g)</code> and confirm your dataframe <code>g</code> has a new column called <code>nObs</code>.</p>

<p>Now use the <code>summary</code> function to print a simple summary of the distribution:</p>

<pre><code class="r">summary(g$nObs)
</code></pre>

<p>The <code>ggplot2</code> library has the ability to make &ldquo;quick plots&rdquo; with the command <code>qplot</code>. If we pass it a single column it will make a histogram of the data for that column. Let&#39;s try it:</p>

<pre><code class="r">qplot(nObs,data=g)
</code></pre>

<p>Our data are from 938 individuals. When the counts are less than this total, it&#39;s because some individuals had array data that was difficult to call a genotype for and so no genotype was reported.  </p>

<p><strong>Question:</strong>  Do most of the SNPs have complete data?<br/>
<strong>Question:</strong> What is the lowest count observed?   Is this number in rough agreement with what we know about how the genome-wide missingness rate filter was set to &gt;98.5% of all SNPs </p>

<h3>Calculating genotype and allele frequencies</h3>

<p>Let&#39;s move on to calculating genotype and allele frequencies.  For allele \( A_1 \) we will denote its frequency among all the samples as \( p_1 \), and likewise for \( A_2 \) we will use \( p_2 \). </p>

<pre><code class="r"># Compute genotype frequencies
g &lt;- mutate(g, p11 = nA1A1/nObs , p12 = nA1A2/nObs, p22 = nA2A2/nObs )
# Compute allele frequencies from genotype frequencies
g &lt;- mutate(g, p1 = p11 + 0.5*p12, p2 = p22 + 0.5*p12)
</code></pre>

<p><strong>Question:</strong>  With a partner or group member, discuss whether the equations in the code for \( p_1 \) and \( p_2 \) are correct and if so, why? </p>

<p>Run <code>head(g)</code> again and confirm <code>g</code> now has the extra columns for the genotype and allele frequencies. </p>

<p>And let&#39;s plot the frequency of the major allele (A2) vs the frequency of the minor allele (A1).  The <code>ggplot2</code> library has the ability to make &ldquo;quick plots&rdquo; with the command <code>qplot</code>.  Let&#39;s try it here: </p>

<pre><code class="r">qplot(p1,p2,data=g)
</code></pre>

<p>Notice that \( p_2>p_1 \) (be careful to inspect the axes labels here)  This makes sense because \( A_1 \) is supposed to be the minor (less frequent) allele.  Note also that there is a linear relationship between \( p_2 \) and \( p_1 \)  </p>

<p><strong>Question:</strong>  What is the equation decribing this relationship?</p>

<p>The relationship exists because there are only two alleles - and so their proportions must sum to 1.  The linear relationship you found exists because of this constraint. It also provides a nice check on our work (if \( p_1 \) and \( p_2 \) didn&#39;t sum to 1 it would suggest something is wrong with our code!).  </p>

<h3>Plotting genotype on allele frequencies</h3>

<p>Let&#39;s look at an initial plot of genotype vs allele frequencies.  We could use the base plotting functions, but the following uses the <code>ggplot2</code> commands.  These are a little trickier, but end up being very compact (we need fewer lines of code overall to achieve our desired plot). To use <code>ggplot2</code> commands effectively our data need to be what statisticans call &ldquo;tidy&rdquo; (in this case, that means with one row per pair of points we will plot).  </p>

<p>To do this, first we subset the data on the columns we&#39;d like (using the <code>select</code> command and listing the set of columns we want), then we pass this (using the <code>%&gt;%</code> operator) to the <code>melt</code> command which will reformat the data for us, and output it as <code>gTidy</code>:</p>

<pre><code class="r">gTidy&lt;-select(g, c(p1,p11,p12,p22)) %&gt;% melt(id=&#39;p1&#39;,value.name=&quot;Genotype.Proportion&quot;)
head(gTidy)
ggplot(gTidy)+geom_point(aes(x=p1,y=Genotype.Proportion,color=variable,shape=variable))
</code></pre>

<p>Now let&#39;s look at the graph produced.  There is some scatter in the relationship between genotype proportion and allele frequency for any given genotype, but at the same time there is a very regular underlying relationship between these variables. </p>

<p><strong>Question:</strong> What are approximate relationships between \( p_{11} \) vs \( p_1 \), \( p_{12} \) vs \( p_1 \), and \( p_22 \) vs \( p_1 \)?  (Hint: These look like parabolas, which suggests are some very simple quadratic functions of \( p_1 \)). </p>

<p>You might start to recognize that these are the classic relationships that are taught in  introductory biology courses.  If you recall, under assumptions that there is no mutation, no natural selection, infinite population size, no population substructure and no migration, then the genotype frequencies will take on a simple relationship with the allele frequencies.  That is: \( p_{11}=p_1^2 \), \( p_{12}=2p_1(1-p_1) \) and \( p_{22}=(1-p_1)^2 \).  In your basic texts, they typicaly use \( p \) and \( q \) for the frequencies of allele 1 and 2, and present these *Hardy-Wienberg proportions$ as: \( p^2 \),\( 2pq \), and \( q^2 \).  </p>

<p>Another way to think of the Hardy-Weinberg proportions is in the following way.  If the state of an allele (\( A_1 \) vs \( A_2 \)) is <em>independent</em> within a genotype, then the probability of a particular genotype state (such as \( A_1 A_1 \)) will be determined by taking the product of the alleles within it (so \( p_{11}=p_1 p_1 \) or \( p_1^2 \)). </p>

<p>Let&#39;s add to the plot lines that represent Hardy-Weinberg proportions:</p>

<pre><code class="r">ggplot(gTidy)+
  geom_point(aes(x=p1,y=Genotype.Proportion,color=variable,shape=variable))+
  stat_function(fun=function(p) p^2, geom=&quot;line&quot;, colour=&quot;red&quot;,size=2.5) +
  stat_function(fun=function(p) 2*p*(1-p), geom=&quot;line&quot;, colour=&quot;green&quot;,size=2.5) +
  stat_function(fun=function(p) (1-p)^2, geom=&quot;line&quot;, colour=&quot;blue&quot;,size=2.5)
</code></pre>

<p>On average, the data follow the classic theoretical expectations fairly well.  It is pretty remarkable that such a simple theory has some bearing on reality! </p>

<p>By eye, we can see that the fit isn&#39;t perfect though.  There is a systematic deficiency of heterozygotes and excess of homozygotes.  Why?  </p>

<p>Let&#39;s look at this more closely and more formally&hellip; </p>

<h3>Testing Hardy Weinberg</h3>

<p>Pearson&#39;s \( \chi^2 \)-test is a basic statistical test that can be used to see if count data conform to a particular expectation.  It is based on the \( X^2 \)-test statistic:
\[  X^2=\sum_i \frac{(o_i-e_i)^2}{e_i} \]
which follows a \( \chi^2 \) distribution under the null hypothesis that the data are generated from a multinomial distribution with the expected counts given by \( e_i \). </p>

<p>Here we compute the test statistic and obtain its associated p-value (using the <code>pchisq</code> function).  We keep in mind that there is 1 degree of freedom (because we have 3 observations per SNP, but then they have to sum to a single total sample size, and we have to use the data once to get the estimated allele frequency, which reduces us down to 1 degree of freedom).</p>

<pre><code class="r">g&lt;-mutate(g,X2 = (nA1A1-nObs*p1^2)^2/(nObs*p1^2)+(nA1A2-nObs*2*p1*p2)^2/(nObs*2*p1*p2)+(nA2A2-nObs*p2^2)^2/(nObs*p2^2))
g&lt;-mutate(g,pval = 1-pchisq(X2,1))
</code></pre>

<h3>The problem of multiple testing</h3>

<p>Let&#39;s look at the top few p-values:</p>

<pre><code class="r">head(g$pval)
</code></pre>

<p>How should we interpret these?  A p-value gives us the frequency at which that the observed departure from expectations (or a more extreme departure) would occur if the null hypothesis is true.  As an agreed upon standard (of the frequentist paradigm for statistical hypothesis testing), if the data are relatively rare under the null (e.g. p-value &lt; 5%), we reject the null hypothesi, and we would infer that the given SNP departs from Hardy-Weinberg expectations.  This is problematic here though.   The problem is that we are testing many, many SNPs (Use <code>dim(g)</code> to remind yourself how many rows/SNPs are in the dataset).  Even if the null is universally true, 5% of our SNPs would be expected to be rejected using the standard frequentist paradigm.  This is called the multiple testing problem.  As an example, if we have 50,000 SNPs, that all obey the null hypothesis, we would on average naively reject the null for ~2500 SNPs based on the p-values &lt; 0.05.   </p>

<p>We clearly need some methods to deal with the &ldquo;multiple testing problem&rdquo;.  Two frameworks are the Bonferroni approach and false-discovery-rate (FDR) approaches.  We will not say more about these here.  Instead, we will do two simple checks to see though if our data are globally consistent with the null.  </p>

<p>First, let&#39;s see how many tests have p-values less than 0.05.  Is it much larger than the number we&#39;d expect on average given the total number of SNPs and a 5% rate of rejection under the null?  </p>

<pre><code class="r">sum(g$pval&lt;0.05,na.rm=TRUE)
</code></pre>

<p>Wow - we see many more.  This is our first sign that though by eye these data show qualitiative similarities to HW, statistically they are not fitting Hardy-Weinberg well enough. </p>

<p>Let&#39;s look at this another way.  A classic result from Fisher is that under the null hypothesis the p-values of a well-designed test should be distributed uniformly between 0 and 1.  What do we see here? </p>

<pre><code class="r">qplot(pval,data=g)
</code></pre>

<p>The data show an enrichment for small p-values relative to a uniform distribution.  Notice how the whole distribution is shifted towards small values - The data appear to systematically depart from Hardy-Weinberg.  </p>

<h3>Plotting expected vs observed heterozygosity</h3>

<p>To understand this more clearly, let&#39;s make a quick plot of the expected vs observed heterozygosity (the proportion of heterozygotes):</p>

<pre><code class="r">qplot(2*p1*(1-p1),p12,data=g)+geom_abline(intercept=0,slope=1,color=&quot;red&quot;,size=1.5)
</code></pre>

<p>Most of the points fall below the y=x line.  That is, we see a systematic deficiency of heterozygotes (and this implies a concordant excess of homozygotes).  This general pattern is contributing to the departure from HW seen in the \( X^2 \) statistics. </p>

<h3>Discussion: Population subdivision and departures from Hardy-Weinberg expectations</h3>

<p>We might wonder why the departure from Hardy-Weinberg proportional is directional, in that, on average, we are seeing a deficiency of heterozygotes (and excess of homozygotes).  One enlightening way to understand this is by thinking about what Sewall Wright (a former eminent University of Chicago professor) called &ldquo;the correlation of uniting gametes&rdquo;.  To produce an \( A_1 A_1 \) individual we need an \( A_1 \)-bearing sperm and an \( A_1 \)-bearing egg to unite.  If these events were independent of each other, we would expect \( A_1 A_1 \) individuals at the rate predicted by multiplying probabilites, that is, \( p_1^2 \) (an idea we introduced above).  However, what if uniting gametes are positively correlated, in that an A-bearing sperm is more likely to join with an A-bearing egg?  In this case we will have more \( A_1 A_1 \) individuals than predicted by \( 2 p_1^2 \), and conversely fewer \( A_1 A_2 \) individuals than predicted by \( 2 p_1 p_2 \).  If our population is structured somehow such that \( A_1 \) sperm are more likely to meet with \( A_1 \) eggs, then we will have such a positive correlation of uniting gametes, and the resulting excess of homozygotes and deficiency of heterozygotes. </p>

<p>Given the HGDP data is from 52 sub-populations from around the globe, and alleles have some some probability of clustering within populations, a good working hypothesis for the deficiency of heterozygotes in this dataset is the presence of some population structure.  </p>

<p>While statistically significant, the population structure appears to be subtle in absolute terms &mdash; based on our plots, we have seen the genotype proportions are not wildly off from HW proportions. </p>

<p><strong>Question:</strong> As an exercise, compute the average deficiency of heterozygotes relative to the expectated proportion.  This is the average of \[  \frac{2 p_1 (1-p_1)-p_{12}}{2p_1(1-p_1)} \]  What is this number for this data-set?  A common &ldquo;rule-of-thumb&rdquo; for this deficiency in a global sample of humans is approximately 10\%.  Do you find this to be true from the data? </p>

<p>A ~10% difference between expected and observed seems pretty remarkable given these samples are taken from across the globe.  It is a reminder that human populations are not very deeply structured.  Most of the alleles in the sample are globally widespread and not sufficiently geographically clustered to generate correlations among the uniting alleles.  This is because all humans populations derived from an ancestral population in Africa around 100-150 thousand years ago, which is relatively small amount of time for variation across populations to accumulate. </p>

<h3>Finding specific loci that are large departures from Hardy-Weinberg</h3>

<p>Now, let&#39;s ask if we can find any loci that are wild departures from HW proportions.  These might be loci that have erroneous genotypes, or loci that cluster geographically in dramatic ways (such that they have few heterozygotes relative to expectations).</p>

<p>To find these loci, we&#39;ll compute the same relative deficiency you computed above, but let&#39;s look at it per SNP.  This number is referred to as \( F \) by Sewall Wright and has connections directly to correlation coefficients (advanced exercise: Try to work this out!).  If we assume there is no inbreeding within populations, this number is an estimator of \( F_{ST} \) (a quantity that appears often in population genetics).</p>

<p>Let&#39;s add this value to our dataframe and plot how it&#39;s value changes across the chromosome from one end to another:</p>

<pre><code class="r">g&lt;-mutate(g,F=(2*p1*(1-p1)-p12)/(2*p1*(1-p1)))
plot(g$F,xlab=&quot;SNP number&quot;)
</code></pre>

<p>There are a few interesting SNPS that show either a very high or low \( F \) value. </p>

<p>Now, here&#39;s a trick.  When a high or low \( F \) value is due to genotyping error, it likely only effects a single SNP.  However, when there is some population genetic force acting on a region of the genome, it likely effects multiple SNPs in the region.  So let&#39;s try to take a local average in a sliding window of SNPs across the genome, computing an average \( F \) over every 5 consecutive SNPs (in real data analysis we might use 100kb or 0.1cM windows). </p>

<p>The <code>stats::filter</code> command below calls the <code>filter</code> function from the <code>stats</code> library.  The code above instructs the function to take 5 values centered on a focal SNP, weighting them each by 1/5 and then taking the sum.  In this way it produces a local average in a sliding window of 5 SNPs.  Let&#39;s define the <code>movingavg</code> function and then make a plot of its values:</p>

<pre><code class="r">movingavg &lt;- function(x,n=5){stats::filter(x,rep(1/n,n), sides=2)}
</code></pre>

<pre><code class="r">plot(movingavg(g$F),xlab=&quot;SNP number&quot;)
</code></pre>

<p>Wow - there appears to be one large spike where the average \( F \) is approximately 60% in the dataset!</p>

<p>Let&#39;s extract the SNP id for the largest value, and look at the dataframe:</p>

<pre><code class="r">outlier=which (movingavg(g$F) == max(movingavg(g$F),na.rm=TRUE))
g[outlier,]
</code></pre>

<p><strong>Question:</strong> Which SNP is returned?  By inserting the rs id into the UCSC genome browser (<a href="https://genome.ucsc.edu/">https://genome.ucsc.edu/</a>), and following the links, find out what gene this SNP resides near.  The gene names should start with &ldquo;SLC..&rdquo;  What gene is it?</p>

<p><strong>Question:</strong> Carry out a literature search on this gene using the term &ldquo;positive selection&rdquo; and see what you find. It&#39;s thought the high \( F \) value observed here is because natural selection led to a geographic clustering of alleles in this gene region.  Discuss with your partners why this might or might not make sense.   </p>

<h3>Discussion: The outlier reigon</h3>

<p>The region you&#39;ve found is one of the most differentiated betwen human populations that is known.  Notice in your literature search, how it is known to affect skin pigmentation and is thought to contribute to differences in skin pigmentation that are seen between human populations.  Finding strong population structure for alleles that affect external morhological phenotypes is not uncommon when looking at other chromosomes.  Some of the most differentiated genes that exist in humans are those that involve morphological phenotypes - such as skin pigmentation, hair color/thickness, and eye color (the genes OCA2/HERC2, SCL45A2, KITLG, EDAR all come to mind).  Many of these are thought to have arisen due to direct or indirect effects of adaptation to local selective pressures (e.g. adaptation to varing levels of UV exposure, local pathogens, local diets, local mating preferences), though in most cases we still do not yet have a fully convincing understanding of their evolutionary histories.  Regardless of the reasons, it is notable that many of the features that humans see externally in each other (i.e. the morphological differences) are controlled by genes that are outliers in the genome.  At most variant SNPs, the patterns of variation are much closer to those of a single random mating populations than they are at variant sites like EDAR.  Put another way, a genomic perspective shows us many of the differences people see in each other are in a sense, just skin-deep. </p>

<h3>Wrap-up</h3>

<p>Modern population genetics has a lot of additional tools on its workbench, but here using relatively simple and classical ideas combined with genomic-scale data, we have been able to observe and interpret some major features of human genetic diversity.  We have also revisited some basic concepts of probablity and statistics such as indepedence vs correlation, the \( \chi^2 \) test, and the problems of multiple testing. One remarkable thing we saw is that a very simple mathematical model based on assuming independence of alleles of genotypes can predict genotype proportions within ~10% of the true values.  This gives us a hint of how simple mathematical models may be useful even in the face of biological complexity. Finally, we have gained more familiarity with R. We didn&#39;t discuss how genotyping errors that might create Hardy-Weinberg departures, but if we were doing additional analyses, we could use Hardy-Weinberg departures to filter them from our data. It&#39;s common practice to do so, but with a Bonferonni correction and using data from within populations to do the filtering. </p>

<h3>Follow-up activities</h3>

<p>In the &#39;addons&#39; folder, we are including data files that you can explore to gain more experience.  These include global data for other chromosomes (<code>H938_chr*.geno</code>) and the same data but limited to European populations (<code>H938_Euro_chr*.geno</code>).  Here are a few suggested follow-up activities.  It may be wise to split the activities across class members and reconvene after carrying them out.  </p>

<p><strong>Follow-up actvity</strong>: Look at a chromosome from the European-restricted data - is the global deficiency in heterozygosity as strong as it was on the global scale?  Before you begin, what would you expect to see?  </p>

<p><strong>Follow-up activity</strong> Using the European data, do you find any regions of the genome that are outliers for \( F \) on chromosome 2?  Using genome browsers and/or literature searches, can you find what is the likely locus under selection for that region? </p>

<p><strong>Follow-up activity</strong>: Using the global data or the European data, analyze other chromosomes &ndash; do you find other loci that show high \( F \) values?</p>

<h3>References</h3>

<p>Li, Jun Z, Devin M Absher, Hua Tang, Audrey M Southwick, Amanda M Casto, Sohini Ramachandran, Howard M Cann, et al. 2008. “Worldwide Human Relationships Inferred from Genome-Wide Patterns of Variation.” Science 319 (5866): 1100–1104.</p>

<p>Pickrell, Joseph K, Graham Coop, John Novembre, Sridhar Kudaravalli, Jun Z Li, Devin Absher, Balaji S Srinivasan, et al. 2009. “Signals of Recent Positive Selection in a Worldwide Sample of Human Populations.” Genome Research 19 (5): 826–37.</p>

</body>

</html>

